{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilow1\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dynamic_coding_analysis.analysis_pipeline import get_data\n",
    "from tqdm import trange\n",
    "from dynamic_coding_analysis.analysis_pipeline import process_spikes as spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'G:/My Drive/Giocomo Lab/RandomForage/'\n",
    "hist = np.load(base + 'aggregate_data/_histology.npy').item()\n",
    "save_folder = base + 'aggregate_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'Lange'\n",
    "s = '0308_speed_2'\n",
    "data = {}\n",
    "data[m] = {}\n",
    "data[m][s] = {}\n",
    "d = data[m][s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/My Drive/Giocomo Lab/RandomForage/Lange/Lange_0308_speed_2_data.mat\n",
      "dict_keys(['sp', 'post', 'posx', 'lickt', 'trial', 'reward'])\n"
     ]
    }
   ],
   "source": [
    "folder = base + m + '/'\n",
    "data_file = m + '_' + s + '_data.mat'\n",
    "behavior = get_data.loadData(folder + data_file)\n",
    "d['behavior'] = behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lange_0308_speed_2: estimated MEC border as 1000um deep\n"
     ]
    }
   ],
   "source": [
    "# define good cells, store depths\n",
    "# get spiking data\n",
    "sp = behavior['sp']\n",
    "cgs = sp['cgs'].copy()\n",
    "cids = sp['cids'].copy()\n",
    "cells = cids[cgs == 2]\n",
    "\n",
    "# filter and sort by depth\n",
    "if 'spike_depth' in sp.keys():\n",
    "    depth = sp['spike_depth'].copy()\n",
    "    depth_idx = np.argsort(sp['spike_depth'])\n",
    "    cells = cells[depth_idx]\n",
    "    sorted_depth = depth[depth_idx]\n",
    "#     if 'histology' in hist[m][s].keys():\n",
    "#         # get length of probe in MEC\n",
    "#         coords = hist[m][s]['histology']\n",
    "#         v = coords[0][:-1] - coords[1]\n",
    "#         l = np.sqrt(np.sum(np.square(v)))\n",
    "#         cells = cells[sorted_depth <= l]\n",
    "#         d['depth'] = sorted_depth[sorted_depth <= l]\n",
    "#     else:\n",
    "    cells = cells[sorted_depth <= (np.max(depth) - 1000)]\n",
    "    d['depth'] = sorted_depth[sorted_depth <= (np.max(depth) - 1000)]                \n",
    "#     cells = cells[sorted_depth <= 2000]\n",
    "#     d['depth'] = sorted_depth[sorted_depth <= 2000]                \n",
    "    print(m + '_' + s + ': estimated MEC border as 1000um deep')\n",
    "else:\n",
    "    print(m + '_' + s + ': no depth info! All cells included and unsorted.')\n",
    "\n",
    "d['cells'] = cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike matrix size pre behavioral filtering = (100328, 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 56/56 [00:00<00:00, 333.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike matrix size post behavioral filtering = (100328, 47)\n"
     ]
    }
   ],
   "source": [
    "# get behavioral params\n",
    "behave_data = d['behavior']\n",
    "posx = behave_data['posx']\n",
    "post = behave_data['post']\n",
    "trial = get_data.trial_idx(posx)\n",
    "dt = np.unique(np.round(np.diff(post),4))\n",
    "speed = get_data.getSpeed(posx, dt)\n",
    "\n",
    "# filter by trial (Toronto_1115 and Lange 0308)\n",
    "if (m == 'Toronto') & (s == '1115_1'):\n",
    "    trial_idx = trial < 300\n",
    "    posx = posx[trial_idx]\n",
    "    post = post[trial_idx]\n",
    "    speed = speed[trial_idx]\n",
    "    trial = trial[trial_idx]\n",
    "elif (m == 'Lange') & (s == '0308_speed_2'):\n",
    "    trial_idx = (trial <= 100) # & (trial >= 40)\n",
    "    post = post[trial_idx]\n",
    "#     post_offset = post[0]\n",
    "#     post = post - post_offset\n",
    "#     spiket = sp['st'].copy()\n",
    "#     spiket = spiket - post_offset\n",
    "#     sp['st'] = spiket\n",
    "    posx = posx[trial_idx]    \n",
    "    speed = speed[trial_idx]\n",
    "    trial = trial[trial_idx]\n",
    "\n",
    "# get neural params\n",
    "cells = d['cells']\n",
    "sp = behave_data['sp']\n",
    "spiket = sp['st'].copy()\n",
    "cluster_id = sp['clu'].copy()\n",
    "if np.max(spiket) > np.max(post):\n",
    "    cluster_id = cluster_id[spiket <= np.max(post)]\n",
    "    spiket = spiket[spiket <= np.max(post)]\n",
    "\n",
    "# format spike and behavioral data\n",
    "A = np.column_stack((posx, speed, trial, post))\n",
    "B = np.zeros((A.shape[0], cells.shape[0]))\n",
    "print('spike matrix size pre behavioral filtering = ' + str(B.shape))\n",
    "\n",
    "for i in trange(cells.shape[0]):\n",
    "    # get spike times\n",
    "    st = spiket[cluster_id == cells[i]]\n",
    "    B[:, i] = get_data.spiketrain(post, dt, st)\n",
    "\n",
    "# filter by speed\n",
    "def find(x):\n",
    "    return x.nonzero()[0]\n",
    "speed_to_trash = find(speed < 2)\n",
    "keep_idx = np.setdiff1d(np.arange(A.shape[0]), speed_to_trash)\n",
    "A = A[keep_idx, :]\n",
    "B = B[keep_idx, :]\n",
    "\n",
    "# correct track ends\n",
    "neg_pos = find(A[:, 0] < 0)\n",
    "A[neg_pos, 0] = A[neg_pos, 0] + 400\n",
    "plus_pos = find(A[:, 0] >= 400)\n",
    "A[plus_pos, 0] = A[plus_pos, 0] - 400\n",
    "\n",
    "# filter by spikes\n",
    "cells = d['cells']\n",
    "d['cells'] = cells[np.sum(B, axis=0) > 400]\n",
    "B = B[:, np.sum(B, axis=0) > 400]\n",
    "\n",
    "print('spike matrix size post behavioral filtering = ' + str(B.shape))\n",
    "d['A'] = A\n",
    "d['B'] = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(trial_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = d['A']\n",
    "B = d['B']\n",
    "Y, centers = spk.tuning_curve_bytrial(A[:, 0], A[:, 2], B, dt, 5, smooth=True, normalize=False)\n",
    "d['Y_raw'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = d['Y_raw']\n",
    "Y[np.isnan(Y)] = 0.0\n",
    "\n",
    "# normalize and clip at 90th percentile\n",
    "for n in range(Y.shape[-1]):\n",
    "    Yn = Y[:, :, n]\n",
    "    Y[:, :, n] = np.clip(Yn, 0, np.percentile(Yn[Yn > 0], 90))\n",
    "Y = Y - np.min(Y, axis=(0, 1), keepdims=True)\n",
    "Y = Y / np.max(Y, axis=(0, 1), keepdims=True)\n",
    "Y = Y[:, :, np.all(np.isfinite(Y), axis=(0, 1))]\n",
    "d['Y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file names\n",
    "session_name = m + '_' + s\n",
    "FR_file = session_name + '_MEC_FRtensor.npy'\n",
    "spikes_file = session_name + '_MEC_spikes.npy'\n",
    "behavior_file = session_name + '_behavior.npy'\n",
    "cells_file = session_name + '_MEC_cellIDs.npy'\n",
    "\n",
    "# save files\n",
    "np.save(save_folder + 'gap_corrected/' + FR_file, d['Y'])\n",
    "np.save(save_folder + 'gap_corrected/' + spikes_file, d['B'])\n",
    "np.save(save_folder + 'gap_corrected/' + behavior_file, d['A'])    \n",
    "np.save(save_folder + 'gap_corrected/' + cells_file, d['cells'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
